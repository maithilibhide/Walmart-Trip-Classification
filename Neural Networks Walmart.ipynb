{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for multi-class classification of Walmart Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data/processed_train.csv')\n",
    "data2 = pd.read_csv('data/processed_data/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704 704\n",
      "Index(['VisitNumber', 'Weekday', 'Upc', 'ScanCount', 'FinelineNumber',\n",
      "       'FLCount', 'VisitFLCount', 'NumPurchases', 'NumReturns',\n",
      "       'VisitNumPurchases',\n",
      "       ...\n",
      "       'UPC_7874235186.0', 'UPC_7874235187.0', 'UPC_7874235188.0',\n",
      "       'UPC_7874235200.0', 'UPC_7874235201.0', 'UPC_7874235296.0',\n",
      "       'UPC_7874298393.0', 'UPC_7976503128.0', 'UPC_8265750406.0',\n",
      "       'UPC_9518801128.0'],\n",
      "      dtype='object', length=704)\n",
      "Index(['VisitNumber', 'Weekday', 'Upc', 'ScanCount', 'FinelineNumber',\n",
      "       'FLCount', 'VisitFLCount', 'NumPurchases', 'NumReturns',\n",
      "       'VisitNumPurchases',\n",
      "       ...\n",
      "       'UPC_7874235186.0', 'UPC_7874235187.0', 'UPC_7874235188.0',\n",
      "       'UPC_7874235200.0', 'UPC_7874235201.0', 'UPC_7874235296.0',\n",
      "       'UPC_7874298393.0', 'UPC_7976503128.0', 'UPC_8265750406.0',\n",
      "       'UPC_9518801128.0'],\n",
      "      dtype='object', length=704)\n",
      "95674\n"
     ]
    }
   ],
   "source": [
    "#Get features(X) and classes(Y) from data\n",
    "Y = data['TripType']\n",
    "X = data.drop(columns=['TripType'])\n",
    "#X = data[data.columns[1:]].iloc[1:]\n",
    "targets = list(np.unique(Y))\n",
    "input_features = len(X.columns)\n",
    "inp = len(data2.columns)\n",
    "print(input_features, inp)\n",
    "#X2 = data2[data2.columns[1:]].iloc[1:]\n",
    "X2 = data2\n",
    "print(X.columns)\n",
    "print(data2.columns)\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training / testing data using sklearn split for 67-33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling of the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "X2 = sc.fit_transform(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the strings to integers in classes (vector to matrix)\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#for 67-33 split train-->\n",
    "encoder.fit(Y_train)\n",
    "#print(encoder.classes_)\n",
    "#print('----')\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "#print(encoded_Y_train[0:20], len(encoded_Y_train), '----------')\n",
    "#print(encoder.inverse_transform(encoded_Y_train)[0:20], len(encoder.inverse_transform(encoded_Y_train)))\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytrain = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "#for 67-33 split test-->\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytest = np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "print(dummy_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64101 samples, validate on 31573 samples\n",
      "Epoch 1/100\n",
      "64101/64101 [==============================] - 9s 139us/step - loss: 3.1674 - acc: 0.1842 - val_loss: 2.5526 - val_acc: 0.3009\n",
      "Epoch 2/100\n",
      "64101/64101 [==============================] - 8s 119us/step - loss: 2.3436 - acc: 0.3781 - val_loss: 2.0171 - val_acc: 0.4737\n",
      "Epoch 3/100\n",
      "64101/64101 [==============================] - 7s 116us/step - loss: 1.9484 - acc: 0.4758 - val_loss: 1.6744 - val_acc: 0.5571\n",
      "Epoch 4/100\n",
      "64101/64101 [==============================] - 8s 129us/step - loss: 1.6946 - acc: 0.5358 - val_loss: 1.4851 - val_acc: 0.5970\n",
      "Epoch 5/100\n",
      "64101/64101 [==============================] - 9s 136us/step - loss: 1.5442 - acc: 0.5690 - val_loss: 1.3541 - val_acc: 0.6130\n",
      "Epoch 6/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 1.4230 - acc: 0.5975 - val_loss: 1.2881 - val_acc: 0.6223\n",
      "Epoch 7/100\n",
      "64101/64101 [==============================] - 9s 138us/step - loss: 1.3530 - acc: 0.6134 - val_loss: 1.2044 - val_acc: 0.6455\n",
      "Epoch 8/100\n",
      "64101/64101 [==============================] - 9s 139us/step - loss: 1.2747 - acc: 0.6306 - val_loss: 1.1606 - val_acc: 0.6601\n",
      "Epoch 9/100\n",
      "64101/64101 [==============================] - 9s 139us/step - loss: 1.2385 - acc: 0.6386 - val_loss: 1.1330 - val_acc: 0.6688\n",
      "Epoch 10/100\n",
      "64101/64101 [==============================] - 8s 128us/step - loss: 1.1952 - acc: 0.6460 - val_loss: 1.0887 - val_acc: 0.6742\n",
      "Epoch 11/100\n",
      "64101/64101 [==============================] - 7s 107us/step - loss: 1.1599 - acc: 0.6548 - val_loss: 1.0751 - val_acc: 0.6747\n",
      "Epoch 12/100\n",
      "64101/64101 [==============================] - 7s 107us/step - loss: 1.1324 - acc: 0.6603 - val_loss: 1.0602 - val_acc: 0.6781\n",
      "Epoch 13/100\n",
      "64101/64101 [==============================] - 8s 123us/step - loss: 1.1024 - acc: 0.6680 - val_loss: 1.0323 - val_acc: 0.6848\n",
      "Epoch 14/100\n",
      "64101/64101 [==============================] - 9s 144us/step - loss: 1.0762 - acc: 0.6726 - val_loss: 1.0189 - val_acc: 0.6881\n",
      "Epoch 15/100\n",
      "64101/64101 [==============================] - 9s 134us/step - loss: 1.0571 - acc: 0.6765 - val_loss: 1.0026 - val_acc: 0.6907\n",
      "Epoch 16/100\n",
      "64101/64101 [==============================] - 9s 145us/step - loss: 1.0414 - acc: 0.6798 - val_loss: 0.9930 - val_acc: 0.6918\n",
      "Epoch 17/100\n",
      "64101/64101 [==============================] - 8s 122us/step - loss: 1.0204 - acc: 0.6842 - val_loss: 0.9774 - val_acc: 0.6935\n",
      "Epoch 18/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 1.0039 - acc: 0.6890 - val_loss: 0.9695 - val_acc: 0.6958\n",
      "Epoch 19/100\n",
      "64101/64101 [==============================] - 7s 106us/step - loss: 0.9895 - acc: 0.6915 - val_loss: 0.9619 - val_acc: 0.7005\n",
      "Epoch 20/100\n",
      "64101/64101 [==============================] - 7s 112us/step - loss: 0.9769 - acc: 0.6959 - val_loss: 0.9577 - val_acc: 0.6986\n",
      "Epoch 21/100\n",
      "64101/64101 [==============================] - 9s 135us/step - loss: 0.9639 - acc: 0.6962 - val_loss: 0.9466 - val_acc: 0.7022\n",
      "Epoch 22/100\n",
      "64101/64101 [==============================] - 7s 113us/step - loss: 0.9523 - acc: 0.6999 - val_loss: 0.9413 - val_acc: 0.7023\n",
      "Epoch 23/100\n",
      "64101/64101 [==============================] - 8s 126us/step - loss: 0.9404 - acc: 0.7029 - val_loss: 0.9432 - val_acc: 0.7009\n",
      "Epoch 24/100\n",
      "64101/64101 [==============================] - 7s 116us/step - loss: 0.9302 - acc: 0.7047 - val_loss: 0.9335 - val_acc: 0.7041\n",
      "Epoch 25/100\n",
      "64101/64101 [==============================] - 7s 117us/step - loss: 0.9183 - acc: 0.7072 - val_loss: 0.9306 - val_acc: 0.6997\n",
      "Epoch 26/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 0.9129 - acc: 0.7086 - val_loss: 0.9232 - val_acc: 0.7040\n",
      "Epoch 27/100\n",
      "64101/64101 [==============================] - 7s 117us/step - loss: 0.9024 - acc: 0.7087 - val_loss: 0.9205 - val_acc: 0.7042\n",
      "Epoch 28/100\n",
      "64101/64101 [==============================] - 7s 115us/step - loss: 0.8916 - acc: 0.7120 - val_loss: 0.9146 - val_acc: 0.7071\n",
      "Epoch 29/100\n",
      "64101/64101 [==============================] - 8s 122us/step - loss: 0.8856 - acc: 0.7113 - val_loss: 0.9091 - val_acc: 0.7102\n",
      "Epoch 30/100\n",
      "64101/64101 [==============================] - 7s 112us/step - loss: 0.8783 - acc: 0.7163 - val_loss: 0.9051 - val_acc: 0.7103\n",
      "Epoch 31/100\n",
      "64101/64101 [==============================] - 7s 114us/step - loss: 0.8678 - acc: 0.7193 - val_loss: 0.9019 - val_acc: 0.7094\n",
      "Epoch 32/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 0.8618 - acc: 0.7220 - val_loss: 0.8993 - val_acc: 0.7103\n",
      "Epoch 33/100\n",
      "64101/64101 [==============================] - 7s 108us/step - loss: 0.8551 - acc: 0.7219 - val_loss: 0.8957 - val_acc: 0.7091\n",
      "Epoch 34/100\n",
      "64101/64101 [==============================] - 7s 112us/step - loss: 0.8462 - acc: 0.7238 - val_loss: 0.8952 - val_acc: 0.7088\n",
      "Epoch 35/100\n",
      "64101/64101 [==============================] - 7s 115us/step - loss: 0.8429 - acc: 0.7261 - val_loss: 0.8945 - val_acc: 0.7114\n",
      "Epoch 36/100\n",
      "64101/64101 [==============================] - 7s 116us/step - loss: 0.8329 - acc: 0.7279 - val_loss: 0.8899 - val_acc: 0.7108\n",
      "Epoch 37/100\n",
      "64101/64101 [==============================] - 8s 121us/step - loss: 0.8314 - acc: 0.7298 - val_loss: 0.8868 - val_acc: 0.7138\n",
      "Epoch 38/100\n",
      "64101/64101 [==============================] - 8s 121us/step - loss: 0.8240 - acc: 0.7286 - val_loss: 0.8832 - val_acc: 0.7134\n",
      "Epoch 39/100\n",
      "64101/64101 [==============================] - 7s 108us/step - loss: 0.8169 - acc: 0.7316 - val_loss: 0.8825 - val_acc: 0.7146\n",
      "Epoch 40/100\n",
      "64101/64101 [==============================] - 7s 111us/step - loss: 0.8120 - acc: 0.7324 - val_loss: 0.8798 - val_acc: 0.7138\n",
      "Epoch 41/100\n",
      "64101/64101 [==============================] - 8s 124us/step - loss: 0.8059 - acc: 0.7339 - val_loss: 0.8799 - val_acc: 0.7149\n",
      "Epoch 42/100\n",
      "64101/64101 [==============================] - 8s 122us/step - loss: 0.8059 - acc: 0.7337 - val_loss: 0.8765 - val_acc: 0.7146\n",
      "Epoch 43/100\n",
      "64101/64101 [==============================] - 8s 120us/step - loss: 0.7952 - acc: 0.7387 - val_loss: 0.8788 - val_acc: 0.7148\n",
      "Epoch 44/100\n",
      "64101/64101 [==============================] - 8s 122us/step - loss: 0.7921 - acc: 0.7379 - val_loss: 0.8721 - val_acc: 0.7170\n",
      "Epoch 45/100\n",
      "64101/64101 [==============================] - 7s 113us/step - loss: 0.7863 - acc: 0.7370 - val_loss: 0.8732 - val_acc: 0.7163\n",
      "Epoch 46/100\n",
      "64101/64101 [==============================] - 7s 117us/step - loss: 0.7832 - acc: 0.7386 - val_loss: 0.8746 - val_acc: 0.7166\n",
      "Epoch 47/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 0.7770 - acc: 0.7397 - val_loss: 0.8719 - val_acc: 0.7174\n",
      "Epoch 48/100\n",
      "64101/64101 [==============================] - 7s 114us/step - loss: 0.7732 - acc: 0.7419 - val_loss: 0.8724 - val_acc: 0.7179\n",
      "Epoch 49/100\n",
      "64101/64101 [==============================] - 8s 121us/step - loss: 0.7663 - acc: 0.7433 - val_loss: 0.8687 - val_acc: 0.7180\n",
      "Epoch 50/100\n",
      "64101/64101 [==============================] - 7s 107us/step - loss: 0.7667 - acc: 0.7445 - val_loss: 0.8684 - val_acc: 0.7165\n",
      "Epoch 51/100\n",
      "64101/64101 [==============================] - 7s 109us/step - loss: 0.7629 - acc: 0.7444 - val_loss: 0.8670 - val_acc: 0.7165\n",
      "Epoch 52/100\n",
      "64101/64101 [==============================] - 7s 111us/step - loss: 0.7561 - acc: 0.7453 - val_loss: 0.8677 - val_acc: 0.7192\n",
      "Epoch 53/100\n",
      "64101/64101 [==============================] - 7s 113us/step - loss: 0.7541 - acc: 0.7481 - val_loss: 0.8672 - val_acc: 0.7181\n",
      "Epoch 54/100\n",
      "64101/64101 [==============================] - 7s 110us/step - loss: 0.7481 - acc: 0.7478 - val_loss: 0.8658 - val_acc: 0.7184\n",
      "Epoch 55/100\n",
      "64101/64101 [==============================] - 7s 107us/step - loss: 0.7467 - acc: 0.7494 - val_loss: 0.8627 - val_acc: 0.7198\n",
      "Epoch 56/100\n",
      "64101/64101 [==============================] - 7s 112us/step - loss: 0.7384 - acc: 0.7510 - val_loss: 0.8669 - val_acc: 0.7178\n",
      "Epoch 57/100\n",
      "64101/64101 [==============================] - 8s 124us/step - loss: 0.7388 - acc: 0.7530 - val_loss: 0.8685 - val_acc: 0.7192\n",
      "Epoch 58/100\n",
      "64101/64101 [==============================] - 8s 117us/step - loss: 0.7373 - acc: 0.7522 - val_loss: 0.8705 - val_acc: 0.7192\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64101/64101 [==============================] - 8s 121us/step - loss: 0.7315 - acc: 0.7537 - val_loss: 0.8638 - val_acc: 0.7210\n",
      "Epoch 60/100\n",
      "64101/64101 [==============================] - 7s 109us/step - loss: 0.7290 - acc: 0.7556 - val_loss: 0.8643 - val_acc: 0.7205\n",
      "Epoch 61/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.7274 - acc: 0.7564 - val_loss: 0.8640 - val_acc: 0.7230\n",
      "Epoch 62/100\n",
      "64101/64101 [==============================] - 8s 123us/step - loss: 0.7183 - acc: 0.7575 - val_loss: 0.8603 - val_acc: 0.7222\n",
      "Epoch 63/100\n",
      "64101/64101 [==============================] - 7s 113us/step - loss: 0.7173 - acc: 0.7566 - val_loss: 0.8616 - val_acc: 0.7189\n",
      "Epoch 64/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 0.7170 - acc: 0.7578 - val_loss: 0.8601 - val_acc: 0.7219\n",
      "Epoch 65/100\n",
      "64101/64101 [==============================] - 9s 134us/step - loss: 0.7089 - acc: 0.7594 - val_loss: 0.8658 - val_acc: 0.7212\n",
      "Epoch 66/100\n",
      "64101/64101 [==============================] - 7s 112us/step - loss: 0.7086 - acc: 0.7613 - val_loss: 0.8618 - val_acc: 0.7216\n",
      "Epoch 67/100\n",
      "64101/64101 [==============================] - 7s 114us/step - loss: 0.7041 - acc: 0.7602 - val_loss: 0.8599 - val_acc: 0.7211\n",
      "Epoch 68/100\n",
      "64101/64101 [==============================] - 7s 106us/step - loss: 0.7027 - acc: 0.7619 - val_loss: 0.8669 - val_acc: 0.7206\n",
      "Epoch 69/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.7010 - acc: 0.7617 - val_loss: 0.8630 - val_acc: 0.7232\n",
      "Epoch 70/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6990 - acc: 0.7623 - val_loss: 0.8636 - val_acc: 0.7191\n",
      "Epoch 71/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6901 - acc: 0.7637 - val_loss: 0.8609 - val_acc: 0.7214\n",
      "Epoch 72/100\n",
      "64101/64101 [==============================] - 7s 109us/step - loss: 0.6904 - acc: 0.7653 - val_loss: 0.8607 - val_acc: 0.7219\n",
      "Epoch 73/100\n",
      "64101/64101 [==============================] - 7s 104us/step - loss: 0.6866 - acc: 0.7658 - val_loss: 0.8616 - val_acc: 0.7214\n",
      "Epoch 74/100\n",
      "64101/64101 [==============================] - 7s 106us/step - loss: 0.6830 - acc: 0.7686 - val_loss: 0.8625 - val_acc: 0.7223\n",
      "Epoch 75/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6864 - acc: 0.7661 - val_loss: 0.8632 - val_acc: 0.7236\n",
      "Epoch 76/100\n",
      "64101/64101 [==============================] - 7s 104us/step - loss: 0.6804 - acc: 0.7686 - val_loss: 0.8645 - val_acc: 0.7242\n",
      "Epoch 77/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6777 - acc: 0.7699 - val_loss: 0.8619 - val_acc: 0.7221\n",
      "Epoch 78/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6754 - acc: 0.7690 - val_loss: 0.8650 - val_acc: 0.7207\n",
      "Epoch 79/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6739 - acc: 0.7692 - val_loss: 0.8636 - val_acc: 0.7240\n",
      "Epoch 80/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6697 - acc: 0.7708 - val_loss: 0.8625 - val_acc: 0.7234\n",
      "Epoch 81/100\n",
      "64101/64101 [==============================] - 7s 106us/step - loss: 0.6685 - acc: 0.7706 - val_loss: 0.8638 - val_acc: 0.7227\n",
      "Epoch 82/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6656 - acc: 0.7722 - val_loss: 0.8641 - val_acc: 0.7234\n",
      "Epoch 83/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6669 - acc: 0.7722 - val_loss: 0.8633 - val_acc: 0.7222\n",
      "Epoch 84/100\n",
      "64101/64101 [==============================] - 7s 106us/step - loss: 0.6586 - acc: 0.7750 - val_loss: 0.8616 - val_acc: 0.7234\n",
      "Epoch 85/100\n",
      "64101/64101 [==============================] - 7s 104us/step - loss: 0.6591 - acc: 0.7763 - val_loss: 0.8683 - val_acc: 0.7233\n",
      "Epoch 86/100\n",
      "64101/64101 [==============================] - 8s 118us/step - loss: 0.6575 - acc: 0.7747 - val_loss: 0.8652 - val_acc: 0.7230\n",
      "Epoch 87/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6548 - acc: 0.7756 - val_loss: 0.8680 - val_acc: 0.7231\n",
      "Epoch 88/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6562 - acc: 0.7750 - val_loss: 0.8683 - val_acc: 0.7240\n",
      "Epoch 89/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6487 - acc: 0.7779 - val_loss: 0.8696 - val_acc: 0.7247\n",
      "Epoch 90/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6525 - acc: 0.7748 - val_loss: 0.8674 - val_acc: 0.7241\n",
      "Epoch 91/100\n",
      "64101/64101 [==============================] - 7s 108us/step - loss: 0.6452 - acc: 0.7788 - val_loss: 0.8692 - val_acc: 0.7221\n",
      "Epoch 92/100\n",
      "64101/64101 [==============================] - 7s 106us/step - loss: 0.6427 - acc: 0.7806 - val_loss: 0.8708 - val_acc: 0.7244\n",
      "Epoch 93/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6412 - acc: 0.7788 - val_loss: 0.8708 - val_acc: 0.7238\n",
      "Epoch 94/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6396 - acc: 0.7802 - val_loss: 0.8723 - val_acc: 0.7236\n",
      "Epoch 95/100\n",
      "64101/64101 [==============================] - 7s 105us/step - loss: 0.6413 - acc: 0.7815 - val_loss: 0.8698 - val_acc: 0.7235\n",
      "Epoch 96/100\n",
      "64101/64101 [==============================] - 7s 116us/step - loss: 0.6396 - acc: 0.7809 - val_loss: 0.8738 - val_acc: 0.7223\n",
      "Epoch 97/100\n",
      "64101/64101 [==============================] - 8s 123us/step - loss: 0.6344 - acc: 0.7819 - val_loss: 0.8710 - val_acc: 0.7224\n",
      "Epoch 98/100\n",
      "64101/64101 [==============================] - 7s 115us/step - loss: 0.6321 - acc: 0.7833 - val_loss: 0.8705 - val_acc: 0.7239\n",
      "Epoch 99/100\n",
      "64101/64101 [==============================] - 7s 115us/step - loss: 0.6329 - acc: 0.7820 - val_loss: 0.8726 - val_acc: 0.7219\n",
      "Epoch 100/100\n",
      "64101/64101 [==============================] - 7s 116us/step - loss: 0.6325 - acc: 0.7820 - val_loss: 0.8715 - val_acc: 0.7244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10c36fc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'uniform', \n",
    "                     activation = 'relu', input_dim = input_features))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "#classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Dense(units = len(targets), kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'Adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, dummy_ytrain, validation_data=(X_test,dummy_ytest), epochs=100, batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "95674/95674 [==============================] - 10s 105us/step - loss: 0.7646 - acc: 0.7513\n",
      "Epoch 2/75\n",
      "95674/95674 [==============================] - 11s 118us/step - loss: 0.7478 - acc: 0.7512\n",
      "Epoch 3/75\n",
      "95674/95674 [==============================] - 10s 109us/step - loss: 0.7375 - acc: 0.7549\n",
      "Epoch 4/75\n",
      "95674/95674 [==============================] - 11s 112us/step - loss: 0.7285 - acc: 0.7579\n",
      "Epoch 5/75\n",
      "95674/95674 [==============================] - 11s 113us/step - loss: 0.7221 - acc: 0.7586\n",
      "Epoch 6/75\n",
      "95674/95674 [==============================] - 10s 108us/step - loss: 0.7161 - acc: 0.7602\n",
      "Epoch 7/75\n",
      "95674/95674 [==============================] - 10s 107us/step - loss: 0.7146 - acc: 0.7590\n",
      "Epoch 8/75\n",
      "95674/95674 [==============================] - 10s 100us/step - loss: 0.7071 - acc: 0.7612\n",
      "Epoch 9/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.7025 - acc: 0.7610\n",
      "Epoch 10/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.7019 - acc: 0.7622\n",
      "Epoch 11/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.7001 - acc: 0.7622\n",
      "Epoch 12/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6933 - acc: 0.7637\n",
      "Epoch 13/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6898 - acc: 0.7645\n",
      "Epoch 14/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6896 - acc: 0.7655\n",
      "Epoch 15/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6859 - acc: 0.7659\n",
      "Epoch 16/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6811 - acc: 0.7680\n",
      "Epoch 17/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6807 - acc: 0.7670\n",
      "Epoch 18/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6767 - acc: 0.7675\n",
      "Epoch 19/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6771 - acc: 0.7681\n",
      "Epoch 20/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6736 - acc: 0.7696\n",
      "Epoch 21/75\n",
      "95674/95674 [==============================] - 10s 101us/step - loss: 0.6660 - acc: 0.7703\n",
      "Epoch 22/75\n",
      "95674/95674 [==============================] - 10s 104us/step - loss: 0.6710 - acc: 0.7694\n",
      "Epoch 23/75\n",
      "95674/95674 [==============================] - 10s 99us/step - loss: 0.6687 - acc: 0.7683\n",
      "Epoch 24/75\n",
      "95674/95674 [==============================] - 10s 104us/step - loss: 0.6675 - acc: 0.7711\n",
      "Epoch 25/75\n",
      "95674/95674 [==============================] - 11s 110us/step - loss: 0.6631 - acc: 0.7717\n",
      "Epoch 26/75\n",
      "95674/95674 [==============================] - 13s 134us/step - loss: 0.6619 - acc: 0.7708\n",
      "Epoch 27/75\n",
      "95674/95674 [==============================] - 11s 115us/step - loss: 0.6549 - acc: 0.7752\n",
      "Epoch 28/75\n",
      "95674/95674 [==============================] - 10s 109us/step - loss: 0.6560 - acc: 0.7740\n",
      "Epoch 29/75\n",
      "95674/95674 [==============================] - 9s 99us/step - loss: 0.6554 - acc: 0.7738\n",
      "Epoch 30/75\n",
      "95674/95674 [==============================] - 12s 121us/step - loss: 0.6534 - acc: 0.7745\n",
      "Epoch 31/75\n",
      "95674/95674 [==============================] - 10s 107us/step - loss: 0.6536 - acc: 0.7737\n",
      "Epoch 32/75\n",
      "95674/95674 [==============================] - 10s 99us/step - loss: 0.6500 - acc: 0.7745\n",
      "Epoch 33/75\n",
      "95674/95674 [==============================] - 10s 102us/step - loss: 0.6467 - acc: 0.7751\n",
      "Epoch 34/75\n",
      "95674/95674 [==============================] - 11s 119us/step - loss: 0.6457 - acc: 0.7767\n",
      "Epoch 35/75\n",
      "95674/95674 [==============================] - 10s 100us/step - loss: 0.6408 - acc: 0.7778\n",
      "Epoch 36/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6403 - acc: 0.7794\n",
      "Epoch 37/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6365 - acc: 0.7790\n",
      "Epoch 38/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6393 - acc: 0.7784\n",
      "Epoch 39/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.6366 - acc: 0.7783\n",
      "Epoch 40/75\n",
      "95674/95674 [==============================] - 9s 90us/step - loss: 0.6365 - acc: 0.7791\n",
      "Epoch 41/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6326 - acc: 0.7798\n",
      "Epoch 42/75\n",
      "95674/95674 [==============================] - 9s 90us/step - loss: 0.6292 - acc: 0.7816\n",
      "Epoch 43/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6282 - acc: 0.7803\n",
      "Epoch 44/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.6300 - acc: 0.7795\n",
      "Epoch 45/75\n",
      "95674/95674 [==============================] - 9s 90us/step - loss: 0.6275 - acc: 0.7824\n",
      "Epoch 46/75\n",
      "95674/95674 [==============================] - 9s 90us/step - loss: 0.6272 - acc: 0.7827\n",
      "Epoch 47/75\n",
      "95674/95674 [==============================] - 9s 90us/step - loss: 0.6247 - acc: 0.7815\n",
      "Epoch 48/75\n",
      "95674/95674 [==============================] - 9s 90us/step - loss: 0.6218 - acc: 0.7830\n",
      "Epoch 49/75\n",
      "95674/95674 [==============================] - 9s 94us/step - loss: 0.6201 - acc: 0.7828\n",
      "Epoch 50/75\n",
      "95674/95674 [==============================] - 10s 104us/step - loss: 0.6217 - acc: 0.7834\n",
      "Epoch 51/75\n",
      "95674/95674 [==============================] - 11s 110us/step - loss: 0.6185 - acc: 0.7845\n",
      "Epoch 52/75\n",
      "95674/95674 [==============================] - 9s 95us/step - loss: 0.6165 - acc: 0.7843\n",
      "Epoch 53/75\n",
      "95674/95674 [==============================] - 10s 109us/step - loss: 0.6141 - acc: 0.7863\n",
      "Epoch 54/75\n",
      "95674/95674 [==============================] - 11s 111us/step - loss: 0.6142 - acc: 0.7849\n",
      "Epoch 55/75\n",
      "95674/95674 [==============================] - 10s 100us/step - loss: 0.6139 - acc: 0.7853\n",
      "Epoch 56/75\n",
      "95674/95674 [==============================] - 9s 95us/step - loss: 0.6124 - acc: 0.7859\n",
      "Epoch 57/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6090 - acc: 0.7880\n",
      "Epoch 58/75\n",
      "95674/95674 [==============================] - 9s 95us/step - loss: 0.6115 - acc: 0.7863\n",
      "Epoch 59/75\n",
      "95674/95674 [==============================] - 9s 94us/step - loss: 0.6068 - acc: 0.7876\n",
      "Epoch 60/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6052 - acc: 0.7891\n",
      "Epoch 61/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6051 - acc: 0.7896\n",
      "Epoch 62/75\n",
      "95674/95674 [==============================] - 11s 115us/step - loss: 0.6068 - acc: 0.7874\n",
      "Epoch 63/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6088 - acc: 0.7878\n",
      "Epoch 64/75\n",
      "95674/95674 [==============================] - 9s 94us/step - loss: 0.6009 - acc: 0.7898\n",
      "Epoch 65/75\n",
      "95674/95674 [==============================] - 9s 99us/step - loss: 0.6004 - acc: 0.7889\n",
      "Epoch 66/75\n",
      "95674/95674 [==============================] - 9s 93us/step - loss: 0.6000 - acc: 0.7902\n",
      "Epoch 67/75\n",
      "95674/95674 [==============================] - 9s 96us/step - loss: 0.5968 - acc: 0.7915\n",
      "Epoch 68/75\n",
      "95674/95674 [==============================] - 11s 113us/step - loss: 0.5997 - acc: 0.7904\n",
      "Epoch 69/75\n",
      "95674/95674 [==============================] - 9s 97us/step - loss: 0.5977 - acc: 0.7899\n",
      "Epoch 70/75\n",
      "95674/95674 [==============================] - 10s 100us/step - loss: 0.5936 - acc: 0.7912\n",
      "Epoch 71/75\n",
      "95674/95674 [==============================] - 9s 94us/step - loss: 0.5948 - acc: 0.7921\n",
      "Epoch 72/75\n",
      "95674/95674 [==============================] - 11s 114us/step - loss: 0.5961 - acc: 0.7918\n",
      "Epoch 73/75\n",
      "95674/95674 [==============================] - 10s 105us/step - loss: 0.5930 - acc: 0.7922\n",
      "Epoch 74/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.5912 - acc: 0.7921\n",
      "Epoch 75/75\n",
      "95674/95674 [==============================] - 9s 92us/step - loss: 0.5907 - acc: 0.7929\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X, dummy_y, epochs=75, batch_size = 4096)\n",
    "\n",
    "#y_pred = classifier.predict(X_test)\n",
    "y_pred = classifier.predict(X2)\n",
    "\n",
    "##score = classifier.evaluate(X_test, dummy_ytest, batch_size = 64)\n",
    "##print(score)\n",
    "\n",
    "#print (log_loss(Y_test, y_pred, labels = targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.89548961e-06   1.09950757e-04   2.06757424e-04 ...,   2.01317924e-03\n",
      "    1.46419159e-04   1.42216112e-03]\n",
      " [  1.73657807e-03   8.07945500e-04   7.60952884e-04 ...,   7.76012912e-02\n",
      "    5.26812859e-03   3.98885831e-02]\n",
      " [  8.17905820e-05   1.91040300e-07   3.20932614e-08 ...,   1.00662508e-11\n",
      "    1.43495564e-14   9.96635258e-01]\n",
      " ..., \n",
      " [  9.13401891e-06   7.13556787e-08   3.64610964e-09 ...,   4.82938889e-09\n",
      "    1.12057559e-11   1.03561988e-03]\n",
      " [  4.11648438e-10   1.27261535e-10   4.35714714e-10 ...,   9.62975668e-04\n",
      "    3.89640639e-03   5.46565570e-06]\n",
      " [  3.95282418e-11   5.49720495e-18   2.16474720e-14 ...,   2.33249131e-09\n",
      "    2.01140837e-09   5.38856568e-07]]\n",
      "<class 'numpy.ndarray'>\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print (type(y_pred))\n",
    "print (len(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(np.unique(Y))\n",
    "visits = data2.VisitNumber.values #data2 is test dataframe\n",
    "targets = [\"TripType_\" + str(int(i)) for i in targets]\n",
    "out = pd.DataFrame(y_pred, columns = targets, index=None) #y_pred is predicted probs\n",
    "out.insert(0,'VisitNumber',visits)\n",
    "out.to_csv(\"output7_nn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trucated SVD\n",
    "#Get features(X) and classes(Y) from data\n",
    "Y = data['TripType']\n",
    "X = data.drop(columns=['TripType'])\n",
    "\n",
    "svd = TruncatedSVD(n_components=200, n_iter=7, random_state=42)\n",
    "svd = svd.fit(X) \n",
    "X = svd.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training / testing data using sklearn split for 67-33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling of the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "X2 = sc.fit_transform(svd.transform(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the strings to integers in classes (vector to matrix)\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#for 67-33 split train-->\n",
    "encoder.fit(Y_train)\n",
    "#print(encoder.classes_)\n",
    "#print('----')\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "#print(encoded_Y_train[0:20], len(encoded_Y_train), '----------')\n",
    "#print(encoder.inverse_transform(encoded_Y_train)[0:20], len(encoder.inverse_transform(encoded_Y_train)))\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytrain = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "#for 67-33 split test-->\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytest = np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "print(dummy_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64101 samples, validate on 31573 samples\n",
      "Epoch 1/100\n",
      "64101/64101 [==============================] - 5s 71us/step - loss: 3.3667 - acc: 0.0769 - val_loss: 3.0720 - val_acc: 0.2169\n",
      "Epoch 2/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 2.8272 - acc: 0.2949 - val_loss: 2.3613 - val_acc: 0.4498\n",
      "Epoch 3/100\n",
      "64101/64101 [==============================] - 4s 66us/step - loss: 2.1364 - acc: 0.4515 - val_loss: 1.8144 - val_acc: 0.5313\n",
      "Epoch 4/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 1.7624 - acc: 0.5248 - val_loss: 1.5335 - val_acc: 0.5775\n",
      "Epoch 5/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.5538 - acc: 0.5653 - val_loss: 1.3740 - val_acc: 0.6033\n",
      "Epoch 6/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 1.4183 - acc: 0.5946 - val_loss: 1.2498 - val_acc: 0.6370\n",
      "Epoch 7/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 1.3170 - acc: 0.6200 - val_loss: 1.1703 - val_acc: 0.6542\n",
      "Epoch 8/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 1.2469 - acc: 0.6309 - val_loss: 1.1256 - val_acc: 0.6601\n",
      "Epoch 9/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 1.1955 - acc: 0.6424 - val_loss: 1.0804 - val_acc: 0.6714\n",
      "Epoch 10/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 1.1573 - acc: 0.6524 - val_loss: 1.0555 - val_acc: 0.6729\n",
      "Epoch 11/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 1.1288 - acc: 0.6587 - val_loss: 1.0330 - val_acc: 0.6789\n",
      "Epoch 12/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 1.1029 - acc: 0.6637 - val_loss: 1.0183 - val_acc: 0.6819\n",
      "Epoch 13/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 1.0815 - acc: 0.6671 - val_loss: 1.0020 - val_acc: 0.6855\n",
      "Epoch 14/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 1.0611 - acc: 0.6705 - val_loss: 0.9891 - val_acc: 0.6914\n",
      "Epoch 15/100\n",
      "64101/64101 [==============================] - 4s 64us/step - loss: 1.0490 - acc: 0.6733 - val_loss: 0.9853 - val_acc: 0.6840\n",
      "Epoch 16/100\n",
      "64101/64101 [==============================] - 3s 50us/step - loss: 1.0319 - acc: 0.6776 - val_loss: 0.9690 - val_acc: 0.6923\n",
      "Epoch 17/100\n",
      "64101/64101 [==============================] - 3s 50us/step - loss: 1.0210 - acc: 0.6808 - val_loss: 0.9643 - val_acc: 0.6932\n",
      "Epoch 18/100\n",
      "64101/64101 [==============================] - 4s 63us/step - loss: 1.0103 - acc: 0.6817 - val_loss: 0.9542 - val_acc: 0.6954\n",
      "Epoch 19/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.9987 - acc: 0.6820 - val_loss: 0.9470 - val_acc: 0.6977\n",
      "Epoch 20/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.9900 - acc: 0.6861 - val_loss: 0.9416 - val_acc: 0.6996\n",
      "Epoch 21/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.9819 - acc: 0.6881 - val_loss: 0.9351 - val_acc: 0.7003\n",
      "Epoch 22/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.9694 - acc: 0.6914 - val_loss: 0.9291 - val_acc: 0.7012\n",
      "Epoch 23/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.9629 - acc: 0.6950 - val_loss: 0.9254 - val_acc: 0.7028\n",
      "Epoch 24/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.9557 - acc: 0.6951 - val_loss: 0.9241 - val_acc: 0.6992\n",
      "Epoch 25/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.9465 - acc: 0.6967 - val_loss: 0.9180 - val_acc: 0.7013\n",
      "Epoch 26/100\n",
      "64101/64101 [==============================] - 4s 70us/step - loss: 0.9452 - acc: 0.6980 - val_loss: 0.9163 - val_acc: 0.7004\n",
      "Epoch 27/100\n",
      "64101/64101 [==============================] - 4s 63us/step - loss: 0.9298 - acc: 0.7025 - val_loss: 0.9087 - val_acc: 0.7059\n",
      "Epoch 28/100\n",
      "64101/64101 [==============================] - 5s 71us/step - loss: 0.9220 - acc: 0.7011 - val_loss: 0.9034 - val_acc: 0.7059\n",
      "Epoch 29/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.9240 - acc: 0.7007 - val_loss: 0.8996 - val_acc: 0.7058\n",
      "Epoch 30/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.9175 - acc: 0.7004 - val_loss: 0.8955 - val_acc: 0.7066\n",
      "Epoch 31/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.9093 - acc: 0.7060 - val_loss: 0.8950 - val_acc: 0.7049\n",
      "Epoch 32/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.9042 - acc: 0.7068 - val_loss: 0.8918 - val_acc: 0.7055\n",
      "Epoch 33/100\n",
      "64101/64101 [==============================] - 4s 66us/step - loss: 0.8944 - acc: 0.7096 - val_loss: 0.8880 - val_acc: 0.7079\n",
      "Epoch 34/100\n",
      "64101/64101 [==============================] - 4s 64us/step - loss: 0.8922 - acc: 0.7093 - val_loss: 0.8839 - val_acc: 0.7069\n",
      "Epoch 35/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8838 - acc: 0.7117 - val_loss: 0.8797 - val_acc: 0.7082\n",
      "Epoch 36/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8833 - acc: 0.7105 - val_loss: 0.8788 - val_acc: 0.7104\n",
      "Epoch 37/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.8774 - acc: 0.7129 - val_loss: 0.8751 - val_acc: 0.7094\n",
      "Epoch 38/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.8691 - acc: 0.7141 - val_loss: 0.8739 - val_acc: 0.7108\n",
      "Epoch 39/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8701 - acc: 0.7144 - val_loss: 0.8711 - val_acc: 0.7099\n",
      "Epoch 40/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8621 - acc: 0.7174 - val_loss: 0.8687 - val_acc: 0.7120\n",
      "Epoch 41/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8581 - acc: 0.7150 - val_loss: 0.8661 - val_acc: 0.7109\n",
      "Epoch 42/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8570 - acc: 0.7162 - val_loss: 0.8660 - val_acc: 0.7130\n",
      "Epoch 43/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8515 - acc: 0.7190 - val_loss: 0.8625 - val_acc: 0.7129\n",
      "Epoch 44/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8449 - acc: 0.7225 - val_loss: 0.8621 - val_acc: 0.7137\n",
      "Epoch 45/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8462 - acc: 0.7223 - val_loss: 0.8580 - val_acc: 0.7138\n",
      "Epoch 46/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8423 - acc: 0.7225 - val_loss: 0.8582 - val_acc: 0.7120\n",
      "Epoch 47/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.8386 - acc: 0.7203 - val_loss: 0.8550 - val_acc: 0.7162\n",
      "Epoch 48/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8350 - acc: 0.7230 - val_loss: 0.8543 - val_acc: 0.7134\n",
      "Epoch 49/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8310 - acc: 0.7240 - val_loss: 0.8527 - val_acc: 0.7144\n",
      "Epoch 50/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8294 - acc: 0.7253 - val_loss: 0.8507 - val_acc: 0.7170\n",
      "Epoch 51/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8269 - acc: 0.7252 - val_loss: 0.8562 - val_acc: 0.7106\n",
      "Epoch 52/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8227 - acc: 0.7261 - val_loss: 0.8464 - val_acc: 0.7168\n",
      "Epoch 53/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8172 - acc: 0.7279 - val_loss: 0.8477 - val_acc: 0.7144\n",
      "Epoch 54/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.8150 - acc: 0.7286 - val_loss: 0.8463 - val_acc: 0.7164\n",
      "Epoch 55/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8100 - acc: 0.7302 - val_loss: 0.8465 - val_acc: 0.7175\n",
      "Epoch 56/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8145 - acc: 0.7280 - val_loss: 0.8448 - val_acc: 0.7161\n",
      "Epoch 57/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8056 - acc: 0.7294 - val_loss: 0.8439 - val_acc: 0.7188\n",
      "Epoch 58/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8042 - acc: 0.7308 - val_loss: 0.8415 - val_acc: 0.7174\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8024 - acc: 0.7309 - val_loss: 0.8411 - val_acc: 0.7186\n",
      "Epoch 60/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7963 - acc: 0.7333 - val_loss: 0.8427 - val_acc: 0.7163\n",
      "Epoch 61/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7996 - acc: 0.7315 - val_loss: 0.8408 - val_acc: 0.7184\n",
      "Epoch 62/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7938 - acc: 0.7347 - val_loss: 0.8411 - val_acc: 0.7158\n",
      "Epoch 63/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.7939 - acc: 0.7319 - val_loss: 0.8377 - val_acc: 0.7195\n",
      "Epoch 64/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7929 - acc: 0.7341 - val_loss: 0.8366 - val_acc: 0.7177\n",
      "Epoch 65/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7895 - acc: 0.7356 - val_loss: 0.8348 - val_acc: 0.7192\n",
      "Epoch 66/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.7827 - acc: 0.7376 - val_loss: 0.8361 - val_acc: 0.7181\n",
      "Epoch 67/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7832 - acc: 0.7370 - val_loss: 0.8334 - val_acc: 0.7211\n",
      "Epoch 68/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.7787 - acc: 0.7364 - val_loss: 0.8362 - val_acc: 0.7200\n",
      "Epoch 69/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.7794 - acc: 0.7371 - val_loss: 0.8335 - val_acc: 0.7196\n",
      "Epoch 70/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.7734 - acc: 0.7388 - val_loss: 0.8351 - val_acc: 0.7194\n",
      "Epoch 71/100\n",
      "64101/64101 [==============================] - 4s 66us/step - loss: 0.7753 - acc: 0.7392 - val_loss: 0.8343 - val_acc: 0.7210\n",
      "Epoch 72/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.7728 - acc: 0.7397 - val_loss: 0.8321 - val_acc: 0.7188\n",
      "Epoch 73/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.7684 - acc: 0.7397 - val_loss: 0.8332 - val_acc: 0.7165\n",
      "Epoch 74/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7668 - acc: 0.7418 - val_loss: 0.8299 - val_acc: 0.7206\n",
      "Epoch 75/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7672 - acc: 0.7393 - val_loss: 0.8288 - val_acc: 0.7201\n",
      "Epoch 76/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7626 - acc: 0.7421 - val_loss: 0.8280 - val_acc: 0.7205\n",
      "Epoch 77/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.7603 - acc: 0.7446 - val_loss: 0.8276 - val_acc: 0.7193\n",
      "Epoch 78/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.7622 - acc: 0.7417 - val_loss: 0.8307 - val_acc: 0.7190\n",
      "Epoch 79/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7598 - acc: 0.7412 - val_loss: 0.8262 - val_acc: 0.7202\n",
      "Epoch 80/100\n",
      "64101/64101 [==============================] - 4s 67us/step - loss: 0.7579 - acc: 0.7434 - val_loss: 0.8275 - val_acc: 0.7194\n",
      "Epoch 81/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7556 - acc: 0.7426 - val_loss: 0.8242 - val_acc: 0.7214\n",
      "Epoch 82/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.7513 - acc: 0.7464 - val_loss: 0.8243 - val_acc: 0.7228\n",
      "Epoch 83/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.7500 - acc: 0.7452 - val_loss: 0.8259 - val_acc: 0.7215\n",
      "Epoch 84/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7471 - acc: 0.7465 - val_loss: 0.8265 - val_acc: 0.7216\n",
      "Epoch 85/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7476 - acc: 0.7453 - val_loss: 0.8235 - val_acc: 0.7235\n",
      "Epoch 86/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.7492 - acc: 0.7454 - val_loss: 0.8250 - val_acc: 0.7211\n",
      "Epoch 87/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7414 - acc: 0.7475 - val_loss: 0.8248 - val_acc: 0.7203\n",
      "Epoch 88/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7405 - acc: 0.7458 - val_loss: 0.8226 - val_acc: 0.7224\n",
      "Epoch 89/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7389 - acc: 0.7478 - val_loss: 0.8218 - val_acc: 0.7219\n",
      "Epoch 90/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7425 - acc: 0.7474 - val_loss: 0.8214 - val_acc: 0.7221\n",
      "Epoch 91/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7374 - acc: 0.7495 - val_loss: 0.8216 - val_acc: 0.7231\n",
      "Epoch 92/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.7351 - acc: 0.7502 - val_loss: 0.8241 - val_acc: 0.7224\n",
      "Epoch 93/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.7355 - acc: 0.7491 - val_loss: 0.8234 - val_acc: 0.7237\n",
      "Epoch 94/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7306 - acc: 0.7505 - val_loss: 0.8234 - val_acc: 0.7236\n",
      "Epoch 95/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.7303 - acc: 0.7488 - val_loss: 0.8203 - val_acc: 0.7235\n",
      "Epoch 96/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.7286 - acc: 0.7499 - val_loss: 0.8198 - val_acc: 0.7240\n",
      "Epoch 97/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.7314 - acc: 0.7496 - val_loss: 0.8220 - val_acc: 0.7231\n",
      "Epoch 98/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.7251 - acc: 0.7516 - val_loss: 0.8234 - val_acc: 0.7237\n",
      "Epoch 99/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.7257 - acc: 0.7527 - val_loss: 0.8201 - val_acc: 0.7235\n",
      "Epoch 100/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.7218 - acc: 0.7522 - val_loss: 0.8194 - val_acc: 0.7247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117807eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'uniform', \n",
    "                     activation = 'relu', input_dim = 200))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "#classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Dense(units = len(targets), kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'Adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, dummy_ytrain, validation_data=(X_test,dummy_ytest), epochs=100, batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.8030 - acc: 0.7301\n",
      "Epoch 2/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.7960 - acc: 0.7317\n",
      "Epoch 3/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.7896 - acc: 0.7330\n",
      "Epoch 4/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.7854 - acc: 0.7344\n",
      "Epoch 5/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.7806 - acc: 0.7361\n",
      "Epoch 6/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.7784 - acc: 0.7377\n",
      "Epoch 7/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.7762 - acc: 0.7361\n",
      "Epoch 8/100\n",
      "95674/95674 [==============================] - 5s 54us/step - loss: 0.7729 - acc: 0.7380\n",
      "Epoch 9/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.7725 - acc: 0.7358\n",
      "Epoch 10/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.7670 - acc: 0.7391\n",
      "Epoch 11/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.7655 - acc: 0.7402\n",
      "Epoch 12/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.7645 - acc: 0.7395\n",
      "Epoch 13/100\n",
      "95674/95674 [==============================] - 5s 52us/step - loss: 0.7604 - acc: 0.7417\n",
      "Epoch 14/100\n",
      "95674/95674 [==============================] - 5s 55us/step - loss: 0.7631 - acc: 0.7403\n",
      "Epoch 15/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.7564 - acc: 0.7419\n",
      "Epoch 16/100\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7533 - acc: 0.7428\n",
      "Epoch 17/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.7547 - acc: 0.7420\n",
      "Epoch 18/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.7518 - acc: 0.7425\n",
      "Epoch 19/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.7503 - acc: 0.7436\n",
      "Epoch 20/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.7496 - acc: 0.7427\n",
      "Epoch 21/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.7473 - acc: 0.7450\n",
      "Epoch 22/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.7454 - acc: 0.7440\n",
      "Epoch 23/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7437 - acc: 0.7456\n",
      "Epoch 24/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7417 - acc: 0.7445\n",
      "Epoch 25/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.7421 - acc: 0.7448\n",
      "Epoch 26/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7391 - acc: 0.7461\n",
      "Epoch 27/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7352 - acc: 0.7464\n",
      "Epoch 28/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7349 - acc: 0.7462\n",
      "Epoch 29/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7339 - acc: 0.7477\n",
      "Epoch 30/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7357 - acc: 0.7470\n",
      "Epoch 31/100\n",
      "95674/95674 [==============================] - 5s 47us/step - loss: 0.7326 - acc: 0.7479\n",
      "Epoch 32/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.7326 - acc: 0.7493\n",
      "Epoch 33/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.7299 - acc: 0.7490\n",
      "Epoch 34/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7282 - acc: 0.7485\n",
      "Epoch 35/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7263 - acc: 0.7487\n",
      "Epoch 36/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7281 - acc: 0.7484\n",
      "Epoch 37/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7234 - acc: 0.7496\n",
      "Epoch 38/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.7223 - acc: 0.7508\n",
      "Epoch 39/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.7231 - acc: 0.7488\n",
      "Epoch 40/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7214 - acc: 0.7509\n",
      "Epoch 41/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7169 - acc: 0.7525\n",
      "Epoch 42/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7186 - acc: 0.7520\n",
      "Epoch 43/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7173 - acc: 0.7504\n",
      "Epoch 44/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7153 - acc: 0.7521\n",
      "Epoch 45/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.7139 - acc: 0.7514\n",
      "Epoch 46/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.7158 - acc: 0.7523\n",
      "Epoch 47/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7124 - acc: 0.7529\n",
      "Epoch 48/100\n",
      "95674/95674 [==============================] - 6s 59us/step - loss: 0.7141 - acc: 0.7520: 4s - loss: 0.\n",
      "Epoch 49/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.7115 - acc: 0.7527\n",
      "Epoch 50/100\n",
      "95674/95674 [==============================] - 5s 52us/step - loss: 0.7089 - acc: 0.7534\n",
      "Epoch 51/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.7102 - acc: 0.7533\n",
      "Epoch 52/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.7080 - acc: 0.7540\n",
      "Epoch 53/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.7081 - acc: 0.7540\n",
      "Epoch 54/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.7035 - acc: 0.7560\n",
      "Epoch 55/100\n",
      "95674/95674 [==============================] - 5s 56us/step - loss: 0.7032 - acc: 0.7560\n",
      "Epoch 56/100\n",
      "95674/95674 [==============================] - 5s 56us/step - loss: 0.7076 - acc: 0.7550\n",
      "Epoch 57/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.7033 - acc: 0.7558\n",
      "Epoch 58/100\n",
      "95674/95674 [==============================] - 5s 47us/step - loss: 0.7019 - acc: 0.7551\n",
      "Epoch 59/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.7036 - acc: 0.7543\n",
      "Epoch 60/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.7007 - acc: 0.7561\n",
      "Epoch 61/100\n",
      "95674/95674 [==============================] - 4s 44us/step - loss: 0.7004 - acc: 0.7562\n",
      "Epoch 62/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.6959 - acc: 0.7566\n",
      "Epoch 63/100\n",
      "95674/95674 [==============================] - 4s 45us/step - loss: 0.6983 - acc: 0.7560\n",
      "Epoch 64/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.6974 - acc: 0.7571\n",
      "Epoch 65/100\n",
      "95674/95674 [==============================] - 6s 59us/step - loss: 0.6968 - acc: 0.7583\n",
      "Epoch 66/100\n",
      "95674/95674 [==============================] - 5s 56us/step - loss: 0.6931 - acc: 0.7583\n",
      "Epoch 67/100\n",
      "95674/95674 [==============================] - 5s 55us/step - loss: 0.6924 - acc: 0.7597\n",
      "Epoch 68/100\n",
      "95674/95674 [==============================] - 5s 56us/step - loss: 0.6950 - acc: 0.7583\n",
      "Epoch 69/100\n",
      "95674/95674 [==============================] - 5s 47us/step - loss: 0.6898 - acc: 0.7590\n",
      "Epoch 70/100\n",
      "95674/95674 [==============================] - 5s 57us/step - loss: 0.6906 - acc: 0.7606\n",
      "Epoch 71/100\n",
      "95674/95674 [==============================] - 5s 52us/step - loss: 0.6900 - acc: 0.7592\n",
      "Epoch 72/100\n",
      "95674/95674 [==============================] - 5s 47us/step - loss: 0.6909 - acc: 0.7595\n",
      "Epoch 73/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.6877 - acc: 0.7601\n",
      "Epoch 74/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.6904 - acc: 0.7590\n",
      "Epoch 75/100\n",
      "95674/95674 [==============================] - 6s 58us/step - loss: 0.6884 - acc: 0.7607\n",
      "Epoch 76/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.6905 - acc: 0.7589\n",
      "Epoch 77/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.6854 - acc: 0.7602\n",
      "Epoch 78/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.6858 - acc: 0.7613\n",
      "Epoch 79/100\n",
      "95674/95674 [==============================] - 4s 47us/step - loss: 0.6835 - acc: 0.7603\n",
      "Epoch 80/100\n",
      "95674/95674 [==============================] - 5s 51us/step - loss: 0.6814 - acc: 0.7610\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.6838 - acc: 0.7616\n",
      "Epoch 82/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.6815 - acc: 0.7602\n",
      "Epoch 83/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6832 - acc: 0.7616\n",
      "Epoch 84/100\n",
      "95674/95674 [==============================] - 4s 46us/step - loss: 0.6778 - acc: 0.7618\n",
      "Epoch 85/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6783 - acc: 0.7618\n",
      "Epoch 86/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6778 - acc: 0.7631\n",
      "Epoch 87/100\n",
      "95674/95674 [==============================] - 6s 59us/step - loss: 0.6775 - acc: 0.7632\n",
      "Epoch 88/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6778 - acc: 0.7620\n",
      "Epoch 89/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.6794 - acc: 0.7618\n",
      "Epoch 90/100\n",
      "95674/95674 [==============================] - 5s 47us/step - loss: 0.6756 - acc: 0.7616\n",
      "Epoch 91/100\n",
      "95674/95674 [==============================] - 5s 47us/step - loss: 0.6748 - acc: 0.7641\n",
      "Epoch 92/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6754 - acc: 0.7639\n",
      "Epoch 93/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.6779 - acc: 0.7610\n",
      "Epoch 94/100\n",
      "95674/95674 [==============================] - 5s 53us/step - loss: 0.6769 - acc: 0.7619\n",
      "Epoch 95/100\n",
      "95674/95674 [==============================] - 5s 49us/step - loss: 0.6708 - acc: 0.7633\n",
      "Epoch 96/100\n",
      "95674/95674 [==============================] - 5s 50us/step - loss: 0.6723 - acc: 0.7641\n",
      "Epoch 97/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6709 - acc: 0.7647\n",
      "Epoch 98/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6709 - acc: 0.7653\n",
      "Epoch 99/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6725 - acc: 0.7637\n",
      "Epoch 100/100\n",
      "95674/95674 [==============================] - 5s 48us/step - loss: 0.6671 - acc: 0.7657\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_7_input to have shape (200,) but got array with shape (704,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-61a073348f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#y_pred = classifier.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m##score = classifier.evaluate(X_test, dummy_ytest, batch_size = 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_7_input to have shape (200,) but got array with shape (704,)"
     ]
    }
   ],
   "source": [
    "classifier.fit(X, dummy_y, epochs=75, batch_size = 4096)\n",
    "\n",
    "#y_pred = classifier.predict(X_test)\n",
    "y_pred = classifier.predict(svd.transform(X2))\n",
    "\n",
    "##score = classifier.evaluate(X_test, dummy_ytest, batch_size = 64)\n",
    "##print(score)\n",
    "\n",
    "#print (log_loss(Y_test, y_pred, labels = targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.76374329e-05   2.61327077e-04   1.00500917e-03 ...,   1.26903623e-01\n",
      "    9.59358811e-02   2.96167244e-04]\n",
      " [  2.12006751e-04   6.65093306e-04   1.93292543e-03 ...,   1.92518175e-01\n",
      "    2.47157905e-02   1.42911803e-02]\n",
      " [  2.56727315e-08   5.58559655e-13   3.56907407e-12 ...,   5.07011798e-14\n",
      "    1.09436136e-17   9.99942899e-01]\n",
      " ..., \n",
      " [  5.91528396e-06   1.75345623e-11   1.21378634e-12 ...,   2.26158603e-09\n",
      "    6.18105447e-13   4.04347520e-04]\n",
      " [  1.07475896e-10   2.46216159e-10   2.99787972e-09 ...,   1.74550582e-02\n",
      "    3.51560628e-03   2.99923408e-06]\n",
      " [  2.03383888e-09   6.87553703e-12   4.40295267e-09 ...,   1.81319319e-05\n",
      "    3.21555417e-05   2.26552438e-04]]\n",
      "<class 'numpy.ndarray'>\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print (type(y_pred))\n",
    "print (len(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(np.unique(Y))\n",
    "visits = data2.VisitNumber.values #data2 is test dataframe\n",
    "targets = [\"TripType_\" + str(int(i)) for i in targets]\n",
    "out = pd.DataFrame(y_pred, columns = targets, index=None) #y_pred is predicted probs\n",
    "out.insert(0,'VisitNumber',visits)\n",
    "out.to_csv(\"output/output7_nn_svd.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [ 11  13  14  16 111 123 133 167 191 201] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Get features(X) and classes(Y) from data\n",
    "Y = data['TripType']\n",
    "X = data.drop(columns=['TripType'])\n",
    "\n",
    "#ANOVA F-value\n",
    "skb = SelectKBest(k = 200)\n",
    "skb = skb.fit(X, Y)\n",
    "names = X.columns.values[skb.get_support()] #names of the columns of X whose features are retained\n",
    "X = skb.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training / testing data using sklearn split for 67-33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling of the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "X2 = sc.fit_transform(skb.transform(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the strings to integers in classes (vector to matrix)\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#for 67-33 split train-->\n",
    "encoder.fit(Y_train)\n",
    "#print(encoder.classes_)\n",
    "#print('----')\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "#print(encoded_Y_train[0:20], len(encoded_Y_train), '----------')\n",
    "#print(encoder.inverse_transform(encoded_Y_train)[0:20], len(encoder.inverse_transform(encoded_Y_train)))\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytrain = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "#for 67-33 split test-->\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytest = np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "print(dummy_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64101 samples, validate on 31573 samples\n",
      "Epoch 1/100\n",
      "64101/64101 [==============================] - 5s 72us/step - loss: 3.2826 - acc: 0.2041 - val_loss: 2.6368 - val_acc: 0.3310\n",
      "Epoch 2/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 2.3146 - acc: 0.4025 - val_loss: 1.9163 - val_acc: 0.5095\n",
      "Epoch 3/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 1.8323 - acc: 0.5125 - val_loss: 1.6044 - val_acc: 0.5614\n",
      "Epoch 4/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.6043 - acc: 0.5576 - val_loss: 1.4115 - val_acc: 0.6039\n",
      "Epoch 5/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 1.4568 - acc: 0.5911 - val_loss: 1.2971 - val_acc: 0.6295\n",
      "Epoch 6/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 1.3678 - acc: 0.6128 - val_loss: 1.2467 - val_acc: 0.6308\n",
      "Epoch 7/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.3148 - acc: 0.6229 - val_loss: 1.1763 - val_acc: 0.6511\n",
      "Epoch 8/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 1.2572 - acc: 0.6334 - val_loss: 1.1427 - val_acc: 0.6562\n",
      "Epoch 9/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 1.2203 - acc: 0.6418 - val_loss: 1.1100 - val_acc: 0.6647\n",
      "Epoch 10/100\n",
      "64101/64101 [==============================] - 3s 50us/step - loss: 1.1935 - acc: 0.6484 - val_loss: 1.0792 - val_acc: 0.6733\n",
      "Epoch 11/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 1.1658 - acc: 0.6536 - val_loss: 1.0599 - val_acc: 0.6767\n",
      "Epoch 12/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 1.1440 - acc: 0.6584 - val_loss: 1.0452 - val_acc: 0.6788\n",
      "Epoch 13/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 1.1271 - acc: 0.6601 - val_loss: 1.0319 - val_acc: 0.6832\n",
      "Epoch 14/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 1.1132 - acc: 0.6612 - val_loss: 1.0215 - val_acc: 0.6824\n",
      "Epoch 15/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 1.0953 - acc: 0.6655 - val_loss: 1.0053 - val_acc: 0.6859\n",
      "Epoch 16/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 1.0869 - acc: 0.6674 - val_loss: 1.0027 - val_acc: 0.6864\n",
      "Epoch 17/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 1.0773 - acc: 0.6685 - val_loss: 0.9893 - val_acc: 0.6884\n",
      "Epoch 18/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 1.0644 - acc: 0.6717 - val_loss: 0.9802 - val_acc: 0.6905\n",
      "Epoch 19/100\n",
      "64101/64101 [==============================] - 3s 50us/step - loss: 1.0553 - acc: 0.6723 - val_loss: 0.9743 - val_acc: 0.6906\n",
      "Epoch 20/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.0476 - acc: 0.6725 - val_loss: 0.9683 - val_acc: 0.6923\n",
      "Epoch 21/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 1.0372 - acc: 0.6764 - val_loss: 0.9663 - val_acc: 0.6893\n",
      "Epoch 22/100\n",
      "64101/64101 [==============================] - 4s 69us/step - loss: 1.0304 - acc: 0.6754 - val_loss: 0.9587 - val_acc: 0.6906\n",
      "Epoch 23/100\n",
      "64101/64101 [==============================] - 4s 65us/step - loss: 1.0235 - acc: 0.6778 - val_loss: 0.9513 - val_acc: 0.6933\n",
      "Epoch 24/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 1.0167 - acc: 0.6785 - val_loss: 0.9429 - val_acc: 0.6945\n",
      "Epoch 25/100\n",
      "64101/64101 [==============================] - 4s 63us/step - loss: 1.0054 - acc: 0.6811 - val_loss: 0.9431 - val_acc: 0.6910\n",
      "Epoch 26/100\n",
      "64101/64101 [==============================] - 4s 67us/step - loss: 1.0040 - acc: 0.6822 - val_loss: 0.9399 - val_acc: 0.6930\n",
      "Epoch 27/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.9986 - acc: 0.6813 - val_loss: 0.9293 - val_acc: 0.6973\n",
      "Epoch 28/100\n",
      "64101/64101 [==============================] - 4s 68us/step - loss: 0.9908 - acc: 0.6855 - val_loss: 0.9248 - val_acc: 0.6988\n",
      "Epoch 29/100\n",
      "64101/64101 [==============================] - 4s 67us/step - loss: 0.9848 - acc: 0.6839 - val_loss: 0.9258 - val_acc: 0.6979\n",
      "Epoch 30/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 0.9787 - acc: 0.6862 - val_loss: 0.9187 - val_acc: 0.6996\n",
      "Epoch 31/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.9724 - acc: 0.6879 - val_loss: 0.9137 - val_acc: 0.7013\n",
      "Epoch 32/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.9696 - acc: 0.6894 - val_loss: 0.9141 - val_acc: 0.7001\n",
      "Epoch 33/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.9626 - acc: 0.6911 - val_loss: 0.9079 - val_acc: 0.7011\n",
      "Epoch 34/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.9592 - acc: 0.6918 - val_loss: 0.9072 - val_acc: 0.6994\n",
      "Epoch 35/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.9541 - acc: 0.6932 - val_loss: 0.9034 - val_acc: 0.7024\n",
      "Epoch 36/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9506 - acc: 0.6922 - val_loss: 0.8972 - val_acc: 0.7040\n",
      "Epoch 37/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9432 - acc: 0.6939 - val_loss: 0.8978 - val_acc: 0.7028\n",
      "Epoch 38/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9456 - acc: 0.6925 - val_loss: 0.8922 - val_acc: 0.7044\n",
      "Epoch 39/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.9395 - acc: 0.6940 - val_loss: 0.8910 - val_acc: 0.7066\n",
      "Epoch 40/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9338 - acc: 0.6967 - val_loss: 0.8895 - val_acc: 0.7031\n",
      "Epoch 41/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9304 - acc: 0.6956 - val_loss: 0.8855 - val_acc: 0.7057\n",
      "Epoch 42/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9273 - acc: 0.6969 - val_loss: 0.8836 - val_acc: 0.7071\n",
      "Epoch 43/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9261 - acc: 0.6988 - val_loss: 0.8810 - val_acc: 0.7070\n",
      "Epoch 44/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9252 - acc: 0.6995 - val_loss: 0.8783 - val_acc: 0.7068\n",
      "Epoch 45/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9173 - acc: 0.7009 - val_loss: 0.8773 - val_acc: 0.7072\n",
      "Epoch 46/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9145 - acc: 0.7011 - val_loss: 0.8780 - val_acc: 0.7076\n",
      "Epoch 47/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9115 - acc: 0.7008 - val_loss: 0.8754 - val_acc: 0.7067\n",
      "Epoch 48/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9105 - acc: 0.7022 - val_loss: 0.8702 - val_acc: 0.7086\n",
      "Epoch 49/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9055 - acc: 0.7034 - val_loss: 0.8690 - val_acc: 0.7098\n",
      "Epoch 50/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9019 - acc: 0.7037 - val_loss: 0.8700 - val_acc: 0.7085\n",
      "Epoch 51/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9039 - acc: 0.7029 - val_loss: 0.8690 - val_acc: 0.7089\n",
      "Epoch 52/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.9014 - acc: 0.7016 - val_loss: 0.8652 - val_acc: 0.7099\n",
      "Epoch 53/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8957 - acc: 0.7052 - val_loss: 0.8609 - val_acc: 0.7110\n",
      "Epoch 54/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8962 - acc: 0.7049 - val_loss: 0.8626 - val_acc: 0.7110\n",
      "Epoch 55/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8925 - acc: 0.7043 - val_loss: 0.8590 - val_acc: 0.7105\n",
      "Epoch 56/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8882 - acc: 0.7051 - val_loss: 0.8588 - val_acc: 0.7122\n",
      "Epoch 57/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8871 - acc: 0.7054 - val_loss: 0.8568 - val_acc: 0.7094\n",
      "Epoch 58/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8829 - acc: 0.7091 - val_loss: 0.8579 - val_acc: 0.7114\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8849 - acc: 0.7058 - val_loss: 0.8548 - val_acc: 0.7122\n",
      "Epoch 60/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.8790 - acc: 0.7069 - val_loss: 0.8552 - val_acc: 0.7110\n",
      "Epoch 61/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8774 - acc: 0.7085 - val_loss: 0.8515 - val_acc: 0.7124\n",
      "Epoch 62/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.8755 - acc: 0.7093 - val_loss: 0.8524 - val_acc: 0.7124\n",
      "Epoch 63/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8751 - acc: 0.7074 - val_loss: 0.8495 - val_acc: 0.7135\n",
      "Epoch 64/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.8702 - acc: 0.7096 - val_loss: 0.8491 - val_acc: 0.7131\n",
      "Epoch 65/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.8679 - acc: 0.7105 - val_loss: 0.8471 - val_acc: 0.7150\n",
      "Epoch 66/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.8690 - acc: 0.7102 - val_loss: 0.8488 - val_acc: 0.7140\n",
      "Epoch 67/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8647 - acc: 0.7110 - val_loss: 0.8448 - val_acc: 0.7155\n",
      "Epoch 68/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 0.8607 - acc: 0.7124 - val_loss: 0.8443 - val_acc: 0.7156\n",
      "Epoch 69/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8602 - acc: 0.7136 - val_loss: 0.8450 - val_acc: 0.7144\n",
      "Epoch 70/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8617 - acc: 0.7112 - val_loss: 0.8425 - val_acc: 0.7166\n",
      "Epoch 71/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8573 - acc: 0.7131 - val_loss: 0.8438 - val_acc: 0.7153\n",
      "Epoch 72/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8579 - acc: 0.7156 - val_loss: 0.8408 - val_acc: 0.7157\n",
      "Epoch 73/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.8550 - acc: 0.7137 - val_loss: 0.8411 - val_acc: 0.7147\n",
      "Epoch 74/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8520 - acc: 0.7158 - val_loss: 0.8390 - val_acc: 0.7172\n",
      "Epoch 75/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8536 - acc: 0.7139 - val_loss: 0.8389 - val_acc: 0.7180\n",
      "Epoch 76/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.8509 - acc: 0.7154 - val_loss: 0.8402 - val_acc: 0.7142\n",
      "Epoch 77/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.8509 - acc: 0.7145 - val_loss: 0.8389 - val_acc: 0.7162\n",
      "Epoch 78/100\n",
      "64101/64101 [==============================] - 4s 66us/step - loss: 0.8450 - acc: 0.7159 - val_loss: 0.8400 - val_acc: 0.7145\n",
      "Epoch 79/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.8452 - acc: 0.7170 - val_loss: 0.8360 - val_acc: 0.7164\n",
      "Epoch 80/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8397 - acc: 0.7170 - val_loss: 0.8357 - val_acc: 0.7172\n",
      "Epoch 81/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.8387 - acc: 0.7185 - val_loss: 0.8335 - val_acc: 0.7168\n",
      "Epoch 82/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8406 - acc: 0.7153 - val_loss: 0.8363 - val_acc: 0.7166\n",
      "Epoch 83/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.8423 - acc: 0.7174 - val_loss: 0.8326 - val_acc: 0.7177\n",
      "Epoch 84/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.8371 - acc: 0.7183 - val_loss: 0.8334 - val_acc: 0.7173\n",
      "Epoch 85/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.8371 - acc: 0.7192 - val_loss: 0.8316 - val_acc: 0.7185\n",
      "Epoch 86/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.8368 - acc: 0.7186 - val_loss: 0.8327 - val_acc: 0.7173\n",
      "Epoch 87/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.8375 - acc: 0.7174 - val_loss: 0.8295 - val_acc: 0.7191\n",
      "Epoch 88/100\n",
      "64101/64101 [==============================] - 4s 65us/step - loss: 0.8319 - acc: 0.7193 - val_loss: 0.8314 - val_acc: 0.7166\n",
      "Epoch 89/100\n",
      "64101/64101 [==============================] - 5s 72us/step - loss: 0.8332 - acc: 0.7181 - val_loss: 0.8323 - val_acc: 0.7173\n",
      "Epoch 90/100\n",
      "64101/64101 [==============================] - 4s 68us/step - loss: 0.8301 - acc: 0.7202 - val_loss: 0.8337 - val_acc: 0.7169\n",
      "Epoch 91/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 0.8260 - acc: 0.7208 - val_loss: 0.8285 - val_acc: 0.7178\n",
      "Epoch 92/100\n",
      "64101/64101 [==============================] - 4s 63us/step - loss: 0.8279 - acc: 0.7209 - val_loss: 0.8280 - val_acc: 0.7186\n",
      "Epoch 93/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.8257 - acc: 0.7196 - val_loss: 0.8272 - val_acc: 0.7194\n",
      "Epoch 94/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.8259 - acc: 0.7223 - val_loss: 0.8280 - val_acc: 0.7186\n",
      "Epoch 95/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8246 - acc: 0.7210 - val_loss: 0.8330 - val_acc: 0.7177\n",
      "Epoch 96/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8209 - acc: 0.7235 - val_loss: 0.8259 - val_acc: 0.7205\n",
      "Epoch 97/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.8201 - acc: 0.7224 - val_loss: 0.8243 - val_acc: 0.7195\n",
      "Epoch 98/100\n",
      "64101/64101 [==============================] - 4s 65us/step - loss: 0.8212 - acc: 0.7230 - val_loss: 0.8232 - val_acc: 0.7213\n",
      "Epoch 99/100\n",
      "64101/64101 [==============================] - 5s 72us/step - loss: 0.8208 - acc: 0.7224 - val_loss: 0.8249 - val_acc: 0.7218\n",
      "Epoch 100/100\n",
      "64101/64101 [==============================] - 4s 64us/step - loss: 0.8167 - acc: 0.7235 - val_loss: 0.8264 - val_acc: 0.7195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117fc4400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'uniform', \n",
    "                     activation = 'relu', input_dim = 200))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "#classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Dense(units = len(targets), kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'Adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, dummy_ytrain, validation_data=(X_test,dummy_ytest), epochs=100, batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X, dummy_y, epochs=75, batch_size = 4096)\n",
    "\n",
    "#y_pred = classifier.predict(X_test)\n",
    "y_pred = classifier.predict(X2)\n",
    "\n",
    "##score = classifier.evaluate(X_test, dummy_ytest, batch_size = 64)\n",
    "##print(score)\n",
    "\n",
    "#print (log_loss(Y_test, y_pred, labels = targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.41193930e-04   2.38921348e-04   1.66957572e-04 ...,   4.01559111e-04\n",
      "    2.78175594e-05   1.95693746e-02]\n",
      " [  2.25480660e-04   1.63357501e-04   2.85220085e-05 ...,   1.63690932e-02\n",
      "    9.68142296e-04   3.57328840e-02]\n",
      " [  1.28925658e-05   2.07943231e-07   2.49065302e-08 ...,   1.20248941e-11\n",
      "    5.48838969e-13   9.87099588e-01]\n",
      " ..., \n",
      " [  1.38571762e-04   1.68466840e-06   6.60230697e-08 ...,   8.72840758e-07\n",
      "    2.07964082e-08   5.43073425e-03]\n",
      " [  2.00513384e-09   7.60494168e-10   6.84166057e-09 ...,   5.76538499e-03\n",
      "    1.59583967e-02   3.86177882e-04]\n",
      " [  6.21060690e-06   3.16861133e-08   4.82383484e-06 ...,   1.59193238e-04\n",
      "    5.75031270e-04   6.50571613e-03]]\n",
      "<class 'numpy.ndarray'>\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print (type(y_pred))\n",
    "print (len(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(np.unique(Y))\n",
    "visits = data2.VisitNumber.values #data2 is test dataframe\n",
    "targets = [\"TripType_\" + str(int(i)) for i in targets]\n",
    "out = pd.DataFrame(y_pred, columns = targets, index=None) #y_pred is predicted probs\n",
    "out.insert(0,'VisitNumber',visits)\n",
    "out.to_csv(\"output7_nn_f_anova.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features(X) and classes(Y) from data\n",
    "Y = data['TripType']\n",
    "X = data.drop(columns=['TripType'])\n",
    "\n",
    "#Mutual Information\n",
    "skb = SelectKBest(k = 200, score_func = mutual_info_classif)\n",
    "skb = skb.fit(X, Y)\n",
    "names = X.columns.values[skb.get_support()] #names of the columns of X whose features are retained\n",
    "X = skb.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training / testing data using sklearn split for 67-33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling of the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X = sc.fit_transform(X)\n",
    "X2 = sc.fit_transform(skb.transform(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Convert the strings to integers in classes (vector to matrix)\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#for 67-33 split train-->\n",
    "encoder.fit(Y_train)\n",
    "#print(encoder.classes_)\n",
    "#print('----')\n",
    "encoded_Y_train = encoder.transform(Y_train)\n",
    "#print(encoded_Y_train[0:20], len(encoded_Y_train), '----------')\n",
    "#print(encoder.inverse_transform(encoded_Y_train)[0:20], len(encoder.inverse_transform(encoded_Y_train)))\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytrain = np_utils.to_categorical(encoded_Y_train)\n",
    "\n",
    "#for 67-33 split test-->\n",
    "encoder.fit(Y_test)\n",
    "encoded_Y_test = encoder.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_ytest = np_utils.to_categorical(encoded_Y_test)\n",
    "\n",
    "\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "print(dummy_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64101 samples, validate on 31573 samples\n",
      "Epoch 1/100\n",
      "64101/64101 [==============================] - 4s 64us/step - loss: 3.2340 - acc: 0.2093 - val_loss: 2.5864 - val_acc: 0.3252\n",
      "Epoch 2/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 2.3144 - acc: 0.3950 - val_loss: 1.9779 - val_acc: 0.4829\n",
      "Epoch 3/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.8732 - acc: 0.4968 - val_loss: 1.6548 - val_acc: 0.5533\n",
      "Epoch 4/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.6403 - acc: 0.5513 - val_loss: 1.4711 - val_acc: 0.5932\n",
      "Epoch 5/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 1.5043 - acc: 0.5800 - val_loss: 1.3770 - val_acc: 0.6069\n",
      "Epoch 6/100\n",
      "64101/64101 [==============================] - 3s 48us/step - loss: 1.4129 - acc: 0.5988 - val_loss: 1.3049 - val_acc: 0.6157\n",
      "Epoch 7/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 1.3404 - acc: 0.6161 - val_loss: 1.2234 - val_acc: 0.6468\n",
      "Epoch 8/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 1.2880 - acc: 0.6276 - val_loss: 1.1753 - val_acc: 0.6545\n",
      "Epoch 9/100\n",
      "64101/64101 [==============================] - 3s 48us/step - loss: 1.2522 - acc: 0.6341 - val_loss: 1.1507 - val_acc: 0.6583\n",
      "Epoch 10/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 1.2192 - acc: 0.6387 - val_loss: 1.1228 - val_acc: 0.6616\n",
      "Epoch 11/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 1.1879 - acc: 0.6465 - val_loss: 1.0969 - val_acc: 0.6681\n",
      "Epoch 12/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 1.1751 - acc: 0.6479 - val_loss: 1.0867 - val_acc: 0.6674\n",
      "Epoch 13/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 1.1492 - acc: 0.6529 - val_loss: 1.0660 - val_acc: 0.6706\n",
      "Epoch 14/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 1.1338 - acc: 0.6566 - val_loss: 1.0583 - val_acc: 0.6748\n",
      "Epoch 15/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 1.1197 - acc: 0.6593 - val_loss: 1.0402 - val_acc: 0.6784\n",
      "Epoch 16/100\n",
      "64101/64101 [==============================] - 3s 48us/step - loss: 1.1038 - acc: 0.6621 - val_loss: 1.0380 - val_acc: 0.6738\n",
      "Epoch 17/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 1.0924 - acc: 0.6626 - val_loss: 1.0296 - val_acc: 0.6762\n",
      "Epoch 18/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 1.0848 - acc: 0.6652 - val_loss: 1.0180 - val_acc: 0.6786\n",
      "Epoch 19/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 1.0704 - acc: 0.6687 - val_loss: 1.0080 - val_acc: 0.6840\n",
      "Epoch 20/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 1.0663 - acc: 0.6677 - val_loss: 1.0003 - val_acc: 0.6843\n",
      "Epoch 21/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 1.0564 - acc: 0.6708 - val_loss: 0.9939 - val_acc: 0.6861\n",
      "Epoch 22/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 1.0484 - acc: 0.6734 - val_loss: 0.9867 - val_acc: 0.6858\n",
      "Epoch 23/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 1.0387 - acc: 0.6734 - val_loss: 0.9820 - val_acc: 0.6869\n",
      "Epoch 24/100\n",
      "64101/64101 [==============================] - 4s 62us/step - loss: 1.0330 - acc: 0.6729 - val_loss: 0.9813 - val_acc: 0.6857\n",
      "Epoch 25/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 1.0262 - acc: 0.6762 - val_loss: 0.9718 - val_acc: 0.6909\n",
      "Epoch 26/100\n",
      "64101/64101 [==============================] - 3s 48us/step - loss: 1.0157 - acc: 0.6798 - val_loss: 0.9668 - val_acc: 0.6895\n",
      "Epoch 27/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 1.0123 - acc: 0.6792 - val_loss: 0.9693 - val_acc: 0.6859\n",
      "Epoch 28/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 1.0049 - acc: 0.6801 - val_loss: 0.9584 - val_acc: 0.6894\n",
      "Epoch 29/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.9977 - acc: 0.6809 - val_loss: 0.9553 - val_acc: 0.6926\n",
      "Epoch 30/100\n",
      "64101/64101 [==============================] - 4s 65us/step - loss: 0.9914 - acc: 0.6823 - val_loss: 0.9530 - val_acc: 0.6932\n",
      "Epoch 31/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.9901 - acc: 0.6834 - val_loss: 0.9470 - val_acc: 0.6942\n",
      "Epoch 32/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.9810 - acc: 0.6870 - val_loss: 0.9430 - val_acc: 0.6934\n",
      "Epoch 33/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9769 - acc: 0.6854 - val_loss: 0.9386 - val_acc: 0.6954\n",
      "Epoch 34/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.9707 - acc: 0.6867 - val_loss: 0.9346 - val_acc: 0.6964\n",
      "Epoch 35/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.9670 - acc: 0.6882 - val_loss: 0.9333 - val_acc: 0.6966\n",
      "Epoch 36/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.9640 - acc: 0.6877 - val_loss: 0.9305 - val_acc: 0.6958\n",
      "Epoch 37/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.9584 - acc: 0.6904 - val_loss: 0.9278 - val_acc: 0.6965\n",
      "Epoch 38/100\n",
      "64101/64101 [==============================] - 3s 50us/step - loss: 0.9557 - acc: 0.6894 - val_loss: 0.9221 - val_acc: 0.6983\n",
      "Epoch 39/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.9491 - acc: 0.6925 - val_loss: 0.9208 - val_acc: 0.6988\n",
      "Epoch 40/100\n",
      "64101/64101 [==============================] - 4s 57us/step - loss: 0.9450 - acc: 0.6933 - val_loss: 0.9240 - val_acc: 0.6964\n",
      "Epoch 41/100\n",
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.9441 - acc: 0.6922 - val_loss: 0.9150 - val_acc: 0.7004\n",
      "Epoch 42/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9372 - acc: 0.6947 - val_loss: 0.9103 - val_acc: 0.7031\n",
      "Epoch 43/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.9366 - acc: 0.6932 - val_loss: 0.9106 - val_acc: 0.7035\n",
      "Epoch 44/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9303 - acc: 0.6966 - val_loss: 0.9061 - val_acc: 0.7029\n",
      "Epoch 45/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.9272 - acc: 0.6958 - val_loss: 0.9044 - val_acc: 0.7042\n",
      "Epoch 46/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.9257 - acc: 0.6946 - val_loss: 0.9030 - val_acc: 0.7044\n",
      "Epoch 47/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.9207 - acc: 0.6964 - val_loss: 0.9032 - val_acc: 0.7037\n",
      "Epoch 48/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.9146 - acc: 0.7003 - val_loss: 0.9001 - val_acc: 0.7040\n",
      "Epoch 49/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.9127 - acc: 0.6984 - val_loss: 0.9021 - val_acc: 0.7030\n",
      "Epoch 50/100\n",
      "64101/64101 [==============================] - 3s 52us/step - loss: 0.9137 - acc: 0.7008 - val_loss: 0.8940 - val_acc: 0.7063\n",
      "Epoch 51/100\n",
      "64101/64101 [==============================] - 3s 53us/step - loss: 0.9100 - acc: 0.7004 - val_loss: 0.8957 - val_acc: 0.7040\n",
      "Epoch 52/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.9053 - acc: 0.7005 - val_loss: 0.8939 - val_acc: 0.7050\n",
      "Epoch 53/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.9013 - acc: 0.7016 - val_loss: 0.8923 - val_acc: 0.7065\n",
      "Epoch 54/100\n",
      "64101/64101 [==============================] - 4s 60us/step - loss: 0.9003 - acc: 0.7019 - val_loss: 0.8911 - val_acc: 0.7070\n",
      "Epoch 55/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8971 - acc: 0.7049 - val_loss: 0.8870 - val_acc: 0.7083\n",
      "Epoch 56/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8958 - acc: 0.7024 - val_loss: 0.8920 - val_acc: 0.7047\n",
      "Epoch 57/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8932 - acc: 0.7043 - val_loss: 0.8847 - val_acc: 0.7086\n",
      "Epoch 58/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8908 - acc: 0.7062 - val_loss: 0.8836 - val_acc: 0.7092\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64101/64101 [==============================] - 4s 55us/step - loss: 0.8865 - acc: 0.7070 - val_loss: 0.8850 - val_acc: 0.7074\n",
      "Epoch 60/100\n",
      "64101/64101 [==============================] - 3s 54us/step - loss: 0.8877 - acc: 0.7084 - val_loss: 0.8839 - val_acc: 0.7091\n",
      "Epoch 61/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8831 - acc: 0.7066 - val_loss: 0.8819 - val_acc: 0.7081\n",
      "Epoch 62/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8757 - acc: 0.7086 - val_loss: 0.8804 - val_acc: 0.7080\n",
      "Epoch 63/100\n",
      "64101/64101 [==============================] - 3s 51us/step - loss: 0.8782 - acc: 0.7077 - val_loss: 0.8779 - val_acc: 0.7104\n",
      "Epoch 64/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8753 - acc: 0.7089 - val_loss: 0.8802 - val_acc: 0.7084\n",
      "Epoch 65/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8724 - acc: 0.7095 - val_loss: 0.8755 - val_acc: 0.7106\n",
      "Epoch 66/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8698 - acc: 0.7101 - val_loss: 0.8739 - val_acc: 0.7121\n",
      "Epoch 67/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8716 - acc: 0.7088 - val_loss: 0.8725 - val_acc: 0.7122\n",
      "Epoch 68/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8688 - acc: 0.7117 - val_loss: 0.8730 - val_acc: 0.7106\n",
      "Epoch 69/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8682 - acc: 0.7098 - val_loss: 0.8728 - val_acc: 0.7115\n",
      "Epoch 70/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8645 - acc: 0.7098 - val_loss: 0.8716 - val_acc: 0.7116\n",
      "Epoch 71/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8611 - acc: 0.7112 - val_loss: 0.8715 - val_acc: 0.7127\n",
      "Epoch 72/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8599 - acc: 0.7117 - val_loss: 0.8688 - val_acc: 0.7135\n",
      "Epoch 73/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8596 - acc: 0.7135 - val_loss: 0.8680 - val_acc: 0.7135\n",
      "Epoch 74/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8564 - acc: 0.7133 - val_loss: 0.8701 - val_acc: 0.7132\n",
      "Epoch 75/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8554 - acc: 0.7139 - val_loss: 0.8669 - val_acc: 0.7134\n",
      "Epoch 76/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8521 - acc: 0.7154 - val_loss: 0.8680 - val_acc: 0.7132\n",
      "Epoch 77/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8508 - acc: 0.7130 - val_loss: 0.8636 - val_acc: 0.7149\n",
      "Epoch 78/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8458 - acc: 0.7167 - val_loss: 0.8642 - val_acc: 0.7137\n",
      "Epoch 79/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8474 - acc: 0.7159 - val_loss: 0.8617 - val_acc: 0.7132\n",
      "Epoch 80/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8432 - acc: 0.7154 - val_loss: 0.8619 - val_acc: 0.7128\n",
      "Epoch 81/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8436 - acc: 0.7150 - val_loss: 0.8616 - val_acc: 0.7142\n",
      "Epoch 82/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8431 - acc: 0.7163 - val_loss: 0.8624 - val_acc: 0.7120\n",
      "Epoch 83/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8421 - acc: 0.7163 - val_loss: 0.8621 - val_acc: 0.7139\n",
      "Epoch 84/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8398 - acc: 0.7150 - val_loss: 0.8581 - val_acc: 0.7160\n",
      "Epoch 85/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8382 - acc: 0.7167 - val_loss: 0.8593 - val_acc: 0.7159\n",
      "Epoch 86/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8331 - acc: 0.7187 - val_loss: 0.8604 - val_acc: 0.7139\n",
      "Epoch 87/100\n",
      "64101/64101 [==============================] - 4s 56us/step - loss: 0.8331 - acc: 0.7197 - val_loss: 0.8586 - val_acc: 0.7140\n",
      "Epoch 88/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8346 - acc: 0.7170 - val_loss: 0.8602 - val_acc: 0.7113\n",
      "Epoch 89/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8336 - acc: 0.7191 - val_loss: 0.8596 - val_acc: 0.7137\n",
      "Epoch 90/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8298 - acc: 0.7196 - val_loss: 0.8587 - val_acc: 0.7141\n",
      "Epoch 91/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8272 - acc: 0.7197 - val_loss: 0.8552 - val_acc: 0.7150\n",
      "Epoch 92/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8246 - acc: 0.7210 - val_loss: 0.8538 - val_acc: 0.7161\n",
      "Epoch 93/100\n",
      "64101/64101 [==============================] - 3s 49us/step - loss: 0.8254 - acc: 0.7209 - val_loss: 0.8537 - val_acc: 0.7164\n",
      "Epoch 94/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.8240 - acc: 0.7208 - val_loss: 0.8536 - val_acc: 0.7153\n",
      "Epoch 95/100\n",
      "64101/64101 [==============================] - 4s 59us/step - loss: 0.8241 - acc: 0.7206 - val_loss: 0.8549 - val_acc: 0.7144\n",
      "Epoch 96/100\n",
      "64101/64101 [==============================] - 4s 61us/step - loss: 0.8193 - acc: 0.7217 - val_loss: 0.8524 - val_acc: 0.7167\n",
      "Epoch 97/100\n",
      "64101/64101 [==============================] - 4s 58us/step - loss: 0.8183 - acc: 0.7231 - val_loss: 0.8551 - val_acc: 0.7151\n",
      "Epoch 98/100\n",
      "64101/64101 [==============================] - 4s 67us/step - loss: 0.8180 - acc: 0.7231 - val_loss: 0.8530 - val_acc: 0.7166\n",
      "Epoch 99/100\n",
      "64101/64101 [==============================] - 5s 76us/step - loss: 0.8153 - acc: 0.7229 - val_loss: 0.8530 - val_acc: 0.7156\n",
      "Epoch 100/100\n",
      "64101/64101 [==============================] - 5s 82us/step - loss: 0.8144 - acc: 0.7217 - val_loss: 0.8512 - val_acc: 0.7162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117482630>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'uniform', \n",
    "                     activation = 'relu', input_dim = 200))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "#classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "classifier.add(Dense(units = len(targets), kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'Adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, dummy_ytrain, validation_data=(X_test,dummy_ytest), epochs=100, batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "95674/95674 [==============================] - 9s 91us/step - loss: 0.8633 - acc: 0.7128\n",
      "Epoch 2/75\n",
      "95674/95674 [==============================] - 8s 82us/step - loss: 0.8590 - acc: 0.7119\n",
      "Epoch 3/75\n",
      "95674/95674 [==============================] - 8s 80us/step - loss: 0.8546 - acc: 0.7134\n",
      "Epoch 4/75\n",
      "95674/95674 [==============================] - 7s 76us/step - loss: 0.8499 - acc: 0.7144\n",
      "Epoch 5/75\n",
      "95674/95674 [==============================] - 8s 80us/step - loss: 0.8518 - acc: 0.7132\n",
      "Epoch 6/75\n",
      "95674/95674 [==============================] - 7s 78us/step - loss: 0.8494 - acc: 0.7159\n",
      "Epoch 7/75\n",
      "95674/95674 [==============================] - 7s 68us/step - loss: 0.8452 - acc: 0.7149\n",
      "Epoch 8/75\n",
      "95674/95674 [==============================] - 8s 79us/step - loss: 0.8433 - acc: 0.7160\n",
      "Epoch 9/75\n",
      "95674/95674 [==============================] - 7s 74us/step - loss: 0.8390 - acc: 0.7175\n",
      "Epoch 10/75\n",
      "95674/95674 [==============================] - 7s 73us/step - loss: 0.8370 - acc: 0.7178\n",
      "Epoch 11/75\n",
      "95674/95674 [==============================] - 8s 79us/step - loss: 0.8367 - acc: 0.7178\n",
      "Epoch 12/75\n",
      "95674/95674 [==============================] - 8s 82us/step - loss: 0.8346 - acc: 0.7188\n",
      "Epoch 13/75\n",
      "95674/95674 [==============================] - 7s 77us/step - loss: 0.8343 - acc: 0.7178\n",
      "Epoch 14/75\n",
      "95674/95674 [==============================] - 8s 79us/step - loss: 0.8314 - acc: 0.7199\n",
      "Epoch 15/75\n",
      "95674/95674 [==============================] - 8s 81us/step - loss: 0.8306 - acc: 0.7195\n",
      "Epoch 16/75\n",
      "95674/95674 [==============================] - 8s 82us/step - loss: 0.8280 - acc: 0.7197\n",
      "Epoch 17/75\n",
      "95674/95674 [==============================] - 8s 87us/step - loss: 0.8270 - acc: 0.7206\n",
      "Epoch 18/75\n",
      "95674/95674 [==============================] - 8s 80us/step - loss: 0.8281 - acc: 0.7205\n",
      "Epoch 19/75\n",
      "95674/95674 [==============================] - 7s 70us/step - loss: 0.8255 - acc: 0.7206\n",
      "Epoch 20/75\n",
      "95674/95674 [==============================] - 8s 85us/step - loss: 0.8225 - acc: 0.7205\n",
      "Epoch 21/75\n",
      "95674/95674 [==============================] - 7s 69us/step - loss: 0.8199 - acc: 0.7217\n",
      "Epoch 22/75\n",
      "95674/95674 [==============================] - 6s 65us/step - loss: 0.8201 - acc: 0.7203\n",
      "Epoch 23/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.8201 - acc: 0.7234\n",
      "Epoch 24/75\n",
      "95674/95674 [==============================] - 6s 63us/step - loss: 0.8164 - acc: 0.7213\n",
      "Epoch 25/75\n",
      "95674/95674 [==============================] - 6s 63us/step - loss: 0.8161 - acc: 0.7236\n",
      "Epoch 26/75\n",
      "95674/95674 [==============================] - 7s 71us/step - loss: 0.8161 - acc: 0.7207\n",
      "Epoch 27/75\n",
      "95674/95674 [==============================] - 8s 80us/step - loss: 0.8156 - acc: 0.7223\n",
      "Epoch 28/75\n",
      "95674/95674 [==============================] - 6s 65us/step - loss: 0.8109 - acc: 0.7244\n",
      "Epoch 29/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.8128 - acc: 0.7238\n",
      "Epoch 30/75\n",
      "95674/95674 [==============================] - 7s 74us/step - loss: 0.8095 - acc: 0.7232\n",
      "Epoch 31/75\n",
      "95674/95674 [==============================] - 8s 81us/step - loss: 0.8105 - acc: 0.7252\n",
      "Epoch 32/75\n",
      "95674/95674 [==============================] - 7s 75us/step - loss: 0.8104 - acc: 0.7220\n",
      "Epoch 33/75\n",
      "95674/95674 [==============================] - 7s 77us/step - loss: 0.8069 - acc: 0.7247\n",
      "Epoch 34/75\n",
      "95674/95674 [==============================] - 8s 79us/step - loss: 0.8055 - acc: 0.7257\n",
      "Epoch 35/75\n",
      "95674/95674 [==============================] - 8s 82us/step - loss: 0.8024 - acc: 0.7255\n",
      "Epoch 36/75\n",
      "95674/95674 [==============================] - 8s 81us/step - loss: 0.8024 - acc: 0.7263\n",
      "Epoch 37/75\n",
      "95674/95674 [==============================] - 8s 82us/step - loss: 0.8029 - acc: 0.7259\n",
      "Epoch 38/75\n",
      "95674/95674 [==============================] - 7s 70us/step - loss: 0.7998 - acc: 0.7273\n",
      "Epoch 39/75\n",
      "95674/95674 [==============================] - 7s 78us/step - loss: 0.8005 - acc: 0.7256\n",
      "Epoch 40/75\n",
      "95674/95674 [==============================] - 7s 74us/step - loss: 0.7959 - acc: 0.7285\n",
      "Epoch 41/75\n",
      "95674/95674 [==============================] - 7s 70us/step - loss: 0.7975 - acc: 0.7278\n",
      "Epoch 42/75\n",
      "95674/95674 [==============================] - 6s 68us/step - loss: 0.7953 - acc: 0.7259\n",
      "Epoch 43/75\n",
      "95674/95674 [==============================] - 7s 71us/step - loss: 0.7955 - acc: 0.7270\n",
      "Epoch 44/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.7940 - acc: 0.7276\n",
      "Epoch 45/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.7941 - acc: 0.7275\n",
      "Epoch 46/75\n",
      "95674/95674 [==============================] - 6s 65us/step - loss: 0.7918 - acc: 0.7284\n",
      "Epoch 47/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.7905 - acc: 0.7285\n",
      "Epoch 48/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.7902 - acc: 0.7274\n",
      "Epoch 49/75\n",
      "95674/95674 [==============================] - 6s 64us/step - loss: 0.7888 - acc: 0.7299\n",
      "Epoch 50/75\n",
      "95674/95674 [==============================] - 7s 71us/step - loss: 0.7860 - acc: 0.7303\n",
      "Epoch 51/75\n",
      "95674/95674 [==============================] - 6s 63us/step - loss: 0.7898 - acc: 0.7289\n",
      "Epoch 52/75\n",
      "95674/95674 [==============================] - 6s 62us/step - loss: 0.7864 - acc: 0.7296\n",
      "Epoch 53/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7866 - acc: 0.7288\n",
      "Epoch 54/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7878 - acc: 0.7292\n",
      "Epoch 55/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7853 - acc: 0.7300\n",
      "Epoch 56/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7846 - acc: 0.7313\n",
      "Epoch 57/75\n",
      "95674/95674 [==============================] - 6s 60us/step - loss: 0.7824 - acc: 0.7311\n",
      "Epoch 58/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7811 - acc: 0.7298\n",
      "Epoch 59/75\n",
      "95674/95674 [==============================] - 6s 60us/step - loss: 0.7817 - acc: 0.7307\n",
      "Epoch 60/75\n",
      "95674/95674 [==============================] - 6s 60us/step - loss: 0.7815 - acc: 0.7297\n",
      "Epoch 61/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7797 - acc: 0.7313\n",
      "Epoch 62/75\n",
      "95674/95674 [==============================] - 8s 83us/step - loss: 0.7787 - acc: 0.7330\n",
      "Epoch 63/75\n",
      "95674/95674 [==============================] - 8s 86us/step - loss: 0.7757 - acc: 0.7328\n",
      "Epoch 64/75\n",
      "95674/95674 [==============================] - 7s 78us/step - loss: 0.7764 - acc: 0.7321\n",
      "Epoch 65/75\n",
      "95674/95674 [==============================] - 7s 73us/step - loss: 0.7775 - acc: 0.7326\n",
      "Epoch 66/75\n",
      "95674/95674 [==============================] - 6s 66us/step - loss: 0.7716 - acc: 0.7335\n",
      "Epoch 67/75\n",
      "95674/95674 [==============================] - 7s 78us/step - loss: 0.7760 - acc: 0.7320\n",
      "Epoch 68/75\n",
      "95674/95674 [==============================] - 8s 79us/step - loss: 0.7745 - acc: 0.7331\n",
      "Epoch 69/75\n",
      "95674/95674 [==============================] - 7s 75us/step - loss: 0.7734 - acc: 0.7326\n",
      "Epoch 70/75\n",
      "95674/95674 [==============================] - 6s 63us/step - loss: 0.7716 - acc: 0.7320\n",
      "Epoch 71/75\n",
      "95674/95674 [==============================] - 6s 63us/step - loss: 0.7715 - acc: 0.7326\n",
      "Epoch 72/75\n",
      "95674/95674 [==============================] - 6s 62us/step - loss: 0.7729 - acc: 0.7317\n",
      "Epoch 73/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7683 - acc: 0.7346\n",
      "Epoch 74/75\n",
      "95674/95674 [==============================] - 6s 61us/step - loss: 0.7686 - acc: 0.7334\n",
      "Epoch 75/75\n",
      "95674/95674 [==============================] - 6s 62us/step - loss: 0.7708 - acc: 0.7315\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X, dummy_y, epochs=75, batch_size = 4096)\n",
    "\n",
    "#y_pred = classifier.predict(X_test)\n",
    "y_pred = classifier.predict(X2)\n",
    "\n",
    "##score = classifier.evaluate(X_test, dummy_ytest, batch_size = 64)\n",
    "##print(score)\n",
    "\n",
    "#print (log_loss(Y_test, y_pred, labels = targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.13561309e-05   4.84897791e-05   6.86969943e-05 ...,   1.67121191e-03\n",
      "    4.11342226e-05   8.60248506e-03]\n",
      " [  1.56692264e-03   4.52379572e-05   2.83967984e-05 ...,   1.77219044e-02\n",
      "    1.10528804e-03   3.93831432e-02]\n",
      " [  2.63817742e-06   3.93626678e-08   1.19925248e-09 ...,   4.67315726e-12\n",
      "    2.01823606e-12   9.93685186e-01]\n",
      " ..., \n",
      " [  2.02175870e-04   1.78521191e-06   4.58461713e-08 ...,   1.54845020e-06\n",
      "    1.16178633e-07   5.08883875e-03]\n",
      " [  1.03808329e-09   4.32542135e-09   5.70667114e-09 ...,   7.56094512e-03\n",
      "    1.46945743e-02   8.71775846e-05]\n",
      " [  3.08637209e-06   4.56720328e-10   8.78196886e-07 ...,   1.55533980e-05\n",
      "    4.47973944e-05   2.93651386e-03]]\n",
      "<class 'numpy.ndarray'>\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print (type(y_pred))\n",
    "print (len(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(np.unique(Y))\n",
    "visits = data2.VisitNumber.values #data2 is test dataframe\n",
    "targets = [\"TripType_\" + str(int(i)) for i in targets]\n",
    "out = pd.DataFrame(y_pred, columns = targets, index=None) #y_pred is predicted probs\n",
    "out.insert(0,'VisitNumber',visits)\n",
    "out.to_csv(\"output7_nn_mutual_info.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
